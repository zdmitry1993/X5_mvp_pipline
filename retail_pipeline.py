"""
DATA PIPELINE MVP –¥–ª—è X5 Tech
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ Docker
–ê–≤—Ç–æ—Ä: Dmitry_Z
"""

import pandas as pd
import sqlite3
import json
from datetime import datetime
import os

def main():
    print("=" * 70)
    print("üéØ DATA PIPELINE MVP –¥–ª—è X5 Tech")
    print("   (–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π Trino, Iceberg, MinIO, Flink)")
    print("=" * 70)
    
    # 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –®–ê–ì 0: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    csv_file = "retail_sales.csv"
    
    if not os.path.exists(csv_file):
        print(f"   ‚ùå –§–∞–π–ª {csv_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("   üìù –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏...")
        create_sample_data()
    else:
        print(f"   ‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {csv_file}")
    
    # 1. –ò–ú–ò–¢–ê–¶–ò–Ø: –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (–∫–∞—Å—Å—ã –º–∞–≥–∞–∑–∏–Ω–æ–≤)
    print("\n" + "=" * 70)
    print("1. üì• –ò–°–¢–û–ß–ù–ò–ö –î–ê–ù–ù–´–•")
    print("   - CSV —Ñ–∞–π–ª —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ (–∞–Ω–∞–ª–æ–≥ –ø–æ—Ç–æ–∫–∞ —Å –∫–∞—Å—Å X5)")
    print("   - –§–æ—Ä–º–∞—Ç: OrderID, Date, Product, Category, Sales, Profit")
    
    df = pd.read_csv(csv_file, encoding='windows-1251')
    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df):,} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç
    df['Order Date'] = pd.to_datetime(df['Order Date'], format='%m/%d/%Y')
    
    # 2. –ò–ú–ò–¢–ê–¶–ò–Ø: Apache Flink (–ø–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
    print("\n" + "=" * 70)
    print("2. ‚ö° APACHE FLINK - –ü–û–¢–û–ö–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê")
    print("   - –û–∫–æ–Ω–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è (tumbling window –ø–æ –¥–Ω—è–º)")
    print("   - –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏ —Ä–µ–≥–∏–æ–Ω–∞–º")
    print("   - –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∫–∞–∫ –≤–æ Flink
    df['order_day'] = df['Order Date'].dt.date
    
    daily_agg = df.groupby(['order_day', 'Category', 'Region']).agg({
        'Sales': ['sum', 'mean'],
        'Profit': ['sum', 'mean'],
        'Quantity': 'sum',
        'Order ID': 'nunique'
    }).reset_index()
    
    # –£–ø—Ä–æ—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
    daily_agg.columns = [
        'date', 'category', 'region',
        'total_sales', 'avg_sales',
        'total_profit', 'avg_profit',
        'total_quantity', 'unique_orders'
    ]
    
    print(f"   ‚úÖ –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–æ: {len(daily_agg):,} –∑–∞–ø–∏—Å–µ–π")
    print(f"   üìà –ú–µ—Ç—Ä–∏–∫–∏: –≤—ã—Ä—É—á–∫–∞, –ø—Ä–∏–±—ã–ª—å, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–∫–∞–∑—ã")
    
    # 3. –ò–ú–ò–¢–ê–¶–ò–Ø: Apache Iceberg (—Ç–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
    print("\n" + "=" * 70)
    print("3. üßä APACHE ICEBERG - –•–†–ê–ù–ï–ù–ò–ï –î–ê–ù–ù–´–•")
    print("   - ACID-—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (–≤ production)")
    print("   - Time travel queries (–¥–æ—Å—Ç—É–ø –∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º –¥–∞–Ω–Ω—ã–º)")
    print("   - Schema evolution (—ç–≤–æ–ª—é—Ü–∏—è —Å—Ö–µ–º—ã –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏)")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö Iceberg
    iceberg_metadata = {
        "format-version": 2,
        "table-uuid": "uuid-x5-retail-001",
        "location": "s3://x5-data-lake/retail/sales_daily",
        "current-snapshot-id": 1,
        "snapshots": [
            {
                "snapshot-id": 1,
                "timestamp-ms": int(datetime.now().timestamp() * 1000),
                "manifest-list": "s3://x5-data-lake/retail/metadata/snap-1.avro"
            }
        ],
        "properties": {
            "write.format.default": "parquet",
            "write.parquet.compression-codec": "snappy"
        }
    }
    
    print(f"   ‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Iceberg —Å–æ–∑–¥–∞–Ω—ã (–≤–µ—Ä—Å–∏—è 2)")
    print(f"   üìç –õ–æ–∫–∞—Ü–∏—è: {iceberg_metadata['location']}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    with open('iceberg_metadata.json', 'w') as f:
        json.dump(iceberg_metadata, f, indent=2)
    
    # 4. –ò–ú–ò–¢–ê–¶–ò–Ø: MinIO/S3 (–æ–±—ä–µ–∫—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ)
    print("\n" + "=" * 70)
    print("4. üóÑÔ∏è MINIO / S3 - –û–ë–™–ï–ö–¢–ù–û–ï –•–†–ê–ù–ò–õ–ò–©–ï")
    print("   - –ê–Ω–∞–ª–æ–≥ AWS S3 –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏")
    print("   - –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ Parquet")
    print("   - –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Parquet (—Ñ–æ—Ä–º–∞—Ç –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Iceberg)
    daily_agg.to_parquet('sales_daily.parquet', compression='snappy', index=False)
    
    print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Parquet (—Å–∂–∞—Ç–∏–µ: snappy)")
    print(f"   üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {os.path.getsize('sales_daily.parquet') / 1024:.1f} KB")
    
    # 5. –ò–ú–ò–¢–ê–¶–ò–Ø: Trino (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π SQL)
    print("\n" + "=" * 70)
    print("5. üóÉÔ∏è TRINO - –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ù–´–ô SQL –î–í–ò–ñ–û–ö")
    print("   - –ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º")
    print("   - SQL-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤")
    print("   - –ó–∞–ø—Ä–æ—Å—ã –∫ –¥–∞–Ω–Ω—ã–º –≤ Iceberg —Ç–∞–±–ª–∏—Ü–∞—Ö")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º SQLite –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ SQL-–∑–∞–ø—Ä–æ—Å–æ–≤ Trino
    conn = sqlite3.connect(':memory:')
    daily_agg.to_sql('sales_daily', conn, index=False, if_exists='replace')
    
    # –ü—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–∫–∞–∫ –≤ Trino)
    queries = [
        {
            "name": "–¢–æ–ø-5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –≤—ã—Ä—É—á–∫–µ",
            "sql": """
                SELECT 
                    category,
                    ROUND(SUM(total_sales), 2) as revenue,
                    ROUND(SUM(total_profit), 2) as profit,
                    ROUND(SUM(total_profit) / SUM(total_sales) * 100, 2) as margin_percent
                FROM sales_daily 
                GROUP BY category 
                ORDER BY revenue DESC 
                LIMIT 5
            """
        },
        {
            "name": "–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂ –ø–æ –¥–Ω—è–º",
            "sql": """
                SELECT 
                    date,
                    SUM(total_sales) as daily_revenue,
                    SUM(total_quantity) as daily_items,
                    COUNT(*) as records_count
                FROM sales_daily 
                GROUP BY date 
                ORDER BY date DESC
                LIMIT 7
            """
        },
        {
            "name": "–†–µ–≥–∏–æ–Ω—ã —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –º–∞—Ä–∂–æ–π",
            "sql": """
                SELECT 
                    region,
                    ROUND(SUM(total_sales), 2) as revenue,
                    ROUND(SUM(total_profit), 2) as profit,
                    ROUND(SUM(total_profit) / SUM(total_sales) * 100, 2) as margin_percent
                FROM sales_daily 
                GROUP BY region 
                HAVING revenue > 0
                ORDER BY margin_percent DESC 
                LIMIT 3
            """
        }
    ]
    
    print("\n   üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–• –ó–ê–ü–†–û–°–û–í:")
    
    for i, query in enumerate(queries, 1):
        result = pd.read_sql_query(query["sql"], conn)
        print(f"\n   {i}. {query['name']}:")
        if not result.empty:
            for _, row in result.iterrows():
                print(f"      ‚Ä¢ {row.iloc[0]}: {row.iloc[1]:.2f} ({row.iloc[2]:.2f} –ø—Ä–∏–±—ã–ª—å)")
    
    conn.close()
    
    # 6. –ë–ò–ó–ù–ï–°-–ò–ù–°–ê–ô–¢–´ –¥–ª—è X5
    print("\n" + "=" * 70)
    print("6. üìà –ë–ò–ó–ù–ï–°-–ò–ù–°–ê–ô–¢–´ –î–õ–Ø –†–ò–¢–ï–ô–õ–ê (X5 Group)")
    
    insights = [
        "üîç ABC-–∞–Ω–∞–ª–∏–∑: 20% –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–∞—é—Ç 80% –≤—ã—Ä—É—á–∫–∏ (–ø—Ä–∏–Ω—Ü–∏–ø –ü–∞—Ä–µ—Ç–æ)",
        "üìÖ –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å: –ø–∏–∫ –ø—Ä–æ–¥–∞–∂ –≤ –∫–æ–Ω—Ü–µ –º–µ—Å—è—Ü–∞ (–∑–∞—Ä–ø–ª–∞—Ç—ã)",
        "üìç –ì–µ–æ–≥—Ä–∞—Ñ–∏—è: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Ä–µ–≥–∏–æ–Ω –¥–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –º–∞—Ä–∂—É",
        "üõí –ö–æ—Ä–∑–∏–Ω–∞: Furniture –∏ Technology - —Å–∞–º—ã–µ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
        "üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —Ñ–æ–∫—É—Å –Ω–∞ –≤—ã—Å–æ–∫–æ–º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö –≤ —Ç–æ–ø-—Ä–µ–≥–∏–æ–Ω–∞—Ö"
    ]
    
    for insight in insights:
        print(f"   {insight}")
    
    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "=" * 70)
    print("7. üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É output
    os.makedirs('output', exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    daily_agg.to_csv('output/daily_sales_aggregated.csv', index=False)
    daily_agg.to_parquet('output/daily_sales_aggregated.parquet', index=False)
    
    # –°–æ–∑–¥–∞–µ–º README —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    create_readme(daily_agg)
    
    print("   ‚úÖ daily_sales_aggregated.csv - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    print("   ‚úÖ daily_sales_aggregated.parquet - –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Iceberg")
    print("   ‚úÖ iceberg_metadata.json - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã Iceberg")
    print("   ‚úÖ output/README.md - –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
    
    print("\n" + "=" * 70)
    print("‚úÖ –ö–û–ù–í–ï–ô–ï–† –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
    print("\nüìã –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(df):,}")
    print(f"   ‚Ä¢ –°–æ–∑–¥–∞–Ω–æ –∞–≥—Ä–µ–≥–∞—Ü–∏–π: {len(daily_agg):,}")
    print(f"   ‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–≤–∞—Ä–æ–≤: {daily_agg['category'].nunique()}")
    print(f"   ‚Ä¢ –†–µ–≥–∏–æ–Ω–æ–≤: {daily_agg['region'].nunique()}")
    print(f"   ‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {daily_agg['date'].min()} - {daily_agg['date'].max()}")
    print(f"   ‚Ä¢ –û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞: {daily_agg['total_sales'].sum():.2f}")
    print(f"   ‚Ä¢ –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: {daily_agg['total_profit'].sum():.2f}")
    
    print("\nüéØ –î–õ–Ø –°–û–ë–ï–°–ï–î–û–í–ê–ù–ò–Ø –í X5 TECH:")
    print("   1. –ü–æ–∫–∞–∑–∞–Ω –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –¥–∞–Ω–Ω—ã—Ö –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–æ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")
    print("   2. –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Å—Ç–µ–∫–∞: Flink, Iceberg, S3, Trino")
    print("   3. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω—ã –±–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç—ã –¥–ª—è —Ä–æ–∑–Ω–∏—á–Ω–æ–π —Å–µ—Ç–∏")
    print("   4. –ö–æ–¥ –≥–æ—Ç–æ–≤ –¥–ª—è GitHub –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ")
    
    print("\n" + "=" * 70)

def create_sample_data():
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"""
    import numpy as np
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    np.random.seed(42)
    n_rows = 1000
    
    data = {
        'Row ID': range(1, n_rows + 1),
        'Order ID': [f'CA-2024-{i:06d}' for i in range(1, n_rows + 1)],
        'Order Date': pd.date_range('2024-01-01', periods=n_rows, freq='h').strftime('%m/%d/%Y'),
        'Customer ID': [f'CG-{np.random.randint(10000, 20000)}' for _ in range(n_rows)],
        'Category': np.random.choice(['Furniture', 'Technology', 'Office Supplies'], n_rows),
        'Sub-Category': np.random.choice(['Chairs', 'Phones', 'Paper', 'Binders'], n_rows),
        'Region': np.random.choice(['South', 'West', 'Central', 'East'], n_rows),
        'Sales': np.random.uniform(10, 1000, n_rows).round(2),
        'Profit': np.random.uniform(-50, 300, n_rows).round(2),
        'Quantity': np.random.randint(1, 10, n_rows)
    }
    
    df = pd.DataFrame(data)
    df.to_csv('retail_sales.csv', index=False)
    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {n_rows} —Å—Ç—Ä–æ–∫")

def create_readme(df):
    """–°–æ–∑–¥–∞–µ—Ç README —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—Ä–∞–Ω–µ–µ
    total_transactions = len(df)
    date_range = f"{df['date'].min()} - {df['date'].max()}"
    categories_count = df['category'].nunique()
    regions_count = df['region'].nunique()
    total_sales_sum = df['total_sales'].sum()
    total_profit_sum = df['total_profit'].sum()
    avg_margin = (total_profit_sum / total_sales_sum * 100).round(2) if total_sales_sum > 0 else 0.0
    
    # –°–æ–∑–¥–∞–µ–º README —Å –ø–æ–º–æ—â—å—é –æ–±—ã—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫
    readme_content = "\n".join([
        "# Retail Data Pipeline MVP –¥–ª—è X5 Tech",
        "",
        "## –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞",
        "–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∏—Ç–µ–π–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ü–µ–ø—Ü–∏–π:",
        "- **Apache Flink** - –ø–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞",
        "- **Apache Iceberg** - —Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
        "- **MinIO/S3** - –æ–±—ä–µ–∫—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ",
        "- **Trino** - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π SQL –¥–≤–∏–∂–æ–∫",
        "",
        "## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
        "",
        "### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö",
        f"- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {total_transactions:,}",
        f"- –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {date_range}",
        f"- –ö–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–≤–∞—Ä–æ–≤: {categories_count}",
        f"- –†–µ–≥–∏–æ–Ω–æ–≤: {regions_count}",
        "",
        "### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏",
        f"- –û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞: {total_sales_sum:.2f}",
        f"- –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: {total_profit_sum:.2f}",
        f"- –°—Ä–µ–¥–Ω—è—è –º–∞—Ä–∂–∞: {avg_margin}%",
        "",
        "### –ë–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç—ã –¥–ª—è —Ä–∏—Ç–µ–π–ª–∞",
        "1. **ABC-–∞–Ω–∞–ª–∏–∑**: 20% –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–∞—é—Ç 80% –≤—ã—Ä—É—á–∫–∏",
        "2. **–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å**: –ø–∏–∫ –ø—Ä–æ–¥–∞–∂ –≤ –∫–æ–Ω—Ü–µ –º–µ—Å—è—Ü–∞",
        "3. **–ì–µ–æ–≥—Ä–∞—Ñ–∏—è**: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Ä–µ–≥–∏–æ–Ω - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –º–∞—Ä–∂–∞",
        "4. **–ö–∞—Ç–µ–≥–æ—Ä–∏–∏**: Furniture –∏ Technology - —Å–∞–º—ã–µ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ",
        ""
    ])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    with open('output/README.md', 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    return readme_content

if __name__ == "__main__":
    main()
   